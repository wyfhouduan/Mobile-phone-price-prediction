#train model
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)  #fit train_data

#plot confusion matrix
cm = confusion_matrix(y_test,y_pred)
conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1','Predicted:2','Predicted:3'],index=['Actual:0','Actual:1','Actual:2','Actual:3'])
plt.figure(figsize = (8,5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="YlGnBu")
plt.figure(figsize = (12,8))
plt.show()

true=cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]
false=cm[0,1]+cm[0,2]+cm[0,3]+cm[1,0]+cm[1,2]+cm[1,3]+cm[2,0]+cm[2,1]+cm[2,3]+cm[3,0]+cm[3,1]+cm[3,2]

#report accuracy
print('The acuracy of the model = ', round(true/float(true+false),3))
print('The Missclassification = 1-Accuracy = ', round(1-(true/float(true+false)), 3))

#use cross validation to select optimal features for classifier
from sklearn.feature_selection import RFECV

col = X_train.columns

rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')
rfecv.fit(X_train, y_train.values.ravel())

print("Optimal number of features: %d" % rfecv.n_features_)
print('Selected features: %s' % list(X_train.columns[rfecv.support_]))

# Plot number of features VS. cross-validation scores
plt.figure(figsize=(10,6))
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score (nb of correct classifications)")
plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)
plt.show()


#create and split the new dataset with optimal selected features
df2 = df1[['price_range','clock_speed', 'fc', 'int_memory', 'mobile_wt', 'n_cores', 'pc', 'ram', 'sc_h', 'sc_w', 'talk_time']]

X1 = df2.drop('price_range', axis=1)
y1 = df2.price_range
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)

#train model and make prediction
logreg.fit(X_train1, y_train1)
y_pred_n = logreg.predict(X_test1)


#make the new confusion matrix
cm_n = confusion_matrix(y_test1,y_pred_n)
conf_matrix_n =pd.DataFrame(data=cm_n,columns=['Predicted:0','Predicted:1','Predicted:2','Predicted:3'],index=['Actual:0','Actual:1','Actual:2','Actual:3'])
plt.figure(figsize = (8,5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="YlGnBu")
plt.figure(figsize = (12,8))
plt.show()


#compute succeed and failed classification 
true1 =cm_n[0,0]+cm_n[1,1]+cm_n[2,2]+cm_n[3,3]
false1 =cm_n[0,1]+cm_n[0,2]+cm_n[0,3]+cm_n[1,0]+cm_n[1,2]+cm_n[1,3]+cm_n[2,0]+cm_n[2,1]+cm_n[2,3]+cm_n[3,0]+cm_n[3,1]+cm_n[3,2]


#new correlation heatmap with selected features
df2 = df1[['price_range','clock_speed','fc', 'int_memory', 'mobile_wt', 'n_cores', 'pc', 'ram', 'sc_h', 'sc_w', 'talk_time']]

plt.figure(figsize = (12,8))
corrplot1 = sns.heatmap(df2.corr(), annot=True, cmap='Blues')
corrplot1.set_xticklabels(corrplot1.get_xticklabels(), rotation = 45, horizontalalignment = 'right') 
plt.show()

#train model
tree_clf = DecisionTreeClassifier(random_state=42)
tree_clf.fit(X_train, y_train)

#create function to get accuracy and confusion matrix
def print_score(clf, X_train, y_train, X_test, y_test, train=True, pos_label="Yes"):
    if train == False:
        pred = clf.predict(X_test)
        print("Test Result:\n")        
        print(f"accuracy score: {accuracy_score(y_test, pred)}\n")
        # print(f"Classification Report: \n \tPrecision: {precision_score(y_test, pred)}\n\tRecall Score: {recall_score(y_test, pred)}\n\tF1 score: {f1_score(y_test, pred)}\n")
        print(f"Confusion Matrix: \n {confusion_matrix(y_test, pred)}\n")
        
 #report the result
print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)

pred = tree_clf.predict(X_test)
cm_n = confusion_matrix(y_test,pred)
conf_matrix_n =pd.DataFrame(data=cm_n,columns=['Predicted:0','Predicted:1','Predicted:2','Predicted:3'],index=['Actual:0','Actual:1','Actual:2','Actual:3'])
plt.figure(figsize = (8,5))
sns.heatmap(conf_matrix_n, annot=True, fmt='d', cmap="YlGnBu")
plt.figure(figsize = (12,8))
plt.show()

#train model
rf_clf = RandomForestClassifier(n_estimators=100)
rf_clf.fit(X_train, y_train)

#report the result
print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)

pred = rf_clf.predict(X_test)
cm_n = confusion_matrix(y_test,pred)
conf_matrix_n =pd.DataFrame(data=cm_n,columns=['Predicted:0','Predicted:1','Predicted:2','Predicted:3'],index=['Actual:0','Actual:1','Actual:2','Actual:3'])
plt.figure(figsize = (8,5))
sns.heatmap(conf_matrix_n, annot=True, fmt='d', cmap="YlGnBu")
plt.figure(figsize = (12,8))
plt.show()

#create model
from sklearn import svm
clf = svm.SVC()

clf.fit(X_train, y_train) #train model

y_pred1 = clf.predict(X_test) #get prediction

#Evaluating our model

print(confusion_matrix(y_test,y_pred1))
print(classification_report(y_test,y_pred1))

cm_n = confusion_matrix(y_test,y_pred1)
conf_matrix_n =pd.DataFrame(data=cm_n,columns=['Predicted:0','Predicted:1','Predicted:2','Predicted:3'],index=['Actual:0','Actual:1','Actual:2','Actual:3'])
plt.figure(figsize = (8,5))
sns.heatmap(conf_matrix_n, annot=True, fmt='d', cmap="YlGnBu")
plt.figure(figsize = (12,8))
plt.show()

#train model and make prediction
from sklearn.naive_bayes import GaussianNB
naive_bayes = GaussianNB()
naive_bayes.fit(X_train,y_train)
y_pred2 = naive_bayes.predict(X_test)

#report the result
print(accuracy_score(y_pred2,y_test))
cm = confusion_matrix(y_test,y_pred2)
conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1','Predicted:2','Predicted:3'],index=['Actual:0','Actual:1','Actual:2','Actual:3'])
plt.figure(figsize = (8,5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="YlGnBu")
plt.figure(figsize = (12,8))
plt.show()

#use pca to reduce dimensions 
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca_result = pca.fit_transform(X)
pca.explained_variance_ratio_
X1 = pca_result
y1 = y.copy()
y1 = y1.to_numpy()
NB = GaussianNB()
NB.fit(X1,y1)
pca_result

l, r = X1[:, 0].min() - 1, X1[:, 0].max() + 1
b, t = X1[:, 1].min() - 1, X1[:, 1].max() + 1
n = 200
grid_x, grid_y = np.meshgrid(np.linspace(l, r, n), np.linspace(b, t, n))
test_x = np.column_stack((grid_x.ravel(), grid_y.ravel()))
y_ = NB.predict(test_x)
grid_z = y_.reshape(grid_x.shape)
plt.pcolormesh(grid_x, grid_y, grid_z, cmap=plt.cm.Pastel1)
plt.scatter(X1[:,0],X1[:,1],c=y1,cmap=plt.cm.Oranges,s=50,marker="*")
plt.xlabel("principal component 1")
plt.ylabel("principal component 2")
plt.title("Use Gaussion naive bayes model")
plt.show()
y1_pred3 = NB.predict(X1)
accuracy_score(y1,y1_pred3)

##train model and make prediction
from sklearn.neighbors import KNeighborsClassifier
#choose k = 3
classifier = KNeighborsClassifier(n_neighbors=3)
# Fitting the model
classifier.fit(X_train, y_train)
# Predicting the Test set results
y_pred4 = classifier.predict(X_test)

#get accuracy of the model
print("accuracy is",accuracy_score(y_pred4,y_test))
#report the confusion matrix
cm = confusion_matrix(y_test,y_pred4)
conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1','Predicted:2','Predicted:3'],index=['Actual:0','Actual:1','Actual:2','Actual:3'])
plt.figure(figsize = (8,5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="YlGnBu")
plt.figure(figsize = (12,8))
plt.show()

## Cross Validation
from sklearn.model_selection import cross_val_score

# Trying different K values from 1 till 30 with step by 2
# Choosing the best K value for the given model based on the accuracy obtained
k_list = list(range(1,30,2))

# Creating list of Average Accuracy for each Cross-validation
cv_scores = []

# Performing 7-fold cross validation
for k in k_list:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train, y_train, cv=7, scoring='accuracy')
    cv_scores.append(scores.mean())
    
    #plot the neighbor selection graph to select the best number of neighbors: k
plt.figure()
#plt.figure(figsize=(15,10))
plt.title('The optimal number of neighbors', fontsize=20, fontweight='bold')
plt.xlabel('Number of Neighbors K', fontsize=15)
plt.ylabel('Accuracy', fontsize=15)
sns.set_style("whitegrid")

plt.plot(k_list, cv_scores)
plt.show()
